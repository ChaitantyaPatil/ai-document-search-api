# ğŸš€ AI-Powered Document Search & Q&A API (RAG)

A production-style **FastAPI backend** that allows users to upload documents, perform **semantic search** using embeddings, and ask **natural language questions** answered via a **Retrieval-Augmented Generation (RAG)** pipeline using **Hugging Face LLMs (OpenAI-compatible SDK)**.

---

## âœ¨ Key Features

* ğŸ“„ Upload and process documents
* ğŸ§  Text extraction and chunking
* ğŸ”¢ Embedding generation for document chunks
* ğŸ” Semantic search using cosine similarity
* ğŸ¤– Context-aware Q&A using Hugging Face Router (Qwen LLM)
* âš¡ Async FastAPI APIs with Swagger UI
* ğŸ§± Clean, layered architecture (API, service, repository)

---

## ğŸ§  System Architecture (High Level)

```
User Query
   â†“
Generate Query Embedding
   â†“
Semantic Search (Cosine Similarity)
   â†“
Relevant Document Chunks
   â†“
Prompt Construction
   â†“
Hugging Face LLM (Qwen via Router)
   â†“
Final Answer + Sources
```

---

## ğŸ› ï¸ Tech Stack

* **Backend:** FastAPI, Python
* **AI / NLP:** Sentence Embeddings, RAG
* **LLM:** Hugging Face Router (Qwen â€“ OpenAI compatible)
* **Database:** SQLAlchemy (SQLite / PostgreSQL ready)
* **Vector Search:** In-memory cosine similarity (FAISS ready)
* **Docs:** Swagger / OpenAPI
* **Config:** python-dotenv

---

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ search.py        # Semantic search endpoint
â”‚   â”œâ”€â”€ ask.py           # RAG-based Q&A endpoint
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ config.py        # Environment configuration
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ document_chunk.py
â”‚
â”œâ”€â”€ repositories/
â”‚   â””â”€â”€ chunk_repository.py
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”œâ”€â”€ search_service.py
â”‚   â””â”€â”€ llm_service.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ similarity.py
â”‚   â””â”€â”€ prompt_builder.py
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ session.py
â”‚
â””â”€â”€ main.py
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/<your-username>/ai-document-search-api.git
cd ai-document-search-api
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Environment Variables

Create a `.env` file:

```env
HF_TOKEN=hf_xxxxxxxxxxxxxxxxx
HF_MODEL=Qwen/Qwen3-Coder-Next:novita
```

âš ï¸ **Never commit `.env` to Git**

---

### 5ï¸âƒ£ Run the Application

```bash
uvicorn app.main:app --reload
```

Access:

* API â†’ [http://127.0.0.1:8000](http://127.0.0.1:8000)
* Swagger â†’ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ” Semantic Search API

**POST** `/search`

```json
{
  "query": "What is FastAPI?",
  "top_k": 3
}
```

Returns most relevant document chunks using embeddings.

---

## ğŸ¤– Ask Question (RAG)

**POST** `/ask`

```json
{
  "question": "What is FastAPI used for?"
}
```

### Sample Response

```json
{
  "question": "What is FastAPI used for?",
  "answer": "FastAPI is a modern Python web framework used for building APIs...",
  "sources": [
    {
      "document_id": 1,
      "chunk_id": 12,
      "score": 0.91,
      "text": "FastAPI is a high-performance web framework..."
    }
  ]
}
```

---

## ğŸ” LLM Integration Details

* Uses **Hugging Face Router**
* OpenAI-compatible SDK
* Easy model switching without code changes

```python
client = OpenAI(
    base_url="https://router.huggingface.co/v1",
    api_key=HF_TOKEN,
)
```

---

## ğŸ§¾ Resume Description

> Built an AI-powered document search and Q&A system using FastAPI and Retrieval-Augmented Generation (RAG). Implemented semantic search with embeddings and cosine similarity, and integrated Hugging Face LLMs (Qwen) via OpenAI-compatible APIs to generate context-aware answers from enterprise documents.

---

## ğŸš€ Future Enhancements

* ğŸ”¹ FAISS / Vector DB integration
* ğŸ”¹ Authentication & rate limiting
* ğŸ”¹ Docker & cloud deployment
* ğŸ”¹ Streaming LLM responses
* ğŸ”¹ Multi-document citation ranking

---

## ğŸ‘¤ Author

**Chaitanya Patil**
Software Developer | Backend & AI Enthusiast

---

Just say the word ğŸš€
